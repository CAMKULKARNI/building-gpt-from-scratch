{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76c60db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 06:05:26.150342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752991526.192832   71972 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752991526.208170   71972 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752991526.253539   71972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752991526.253599   71972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752991526.253603   71972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752991526.253606   71972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-20 06:05:26.265074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85821257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "wte = keras.layers.Embedding(input_dim=10, output_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e2ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752991565.181845   71972 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2242 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[-0.02860935,  0.00974352,  0.04084095],\n",
       "       [-0.04977075, -0.03769188, -0.03748412],\n",
       "       [-0.01952647, -0.01114391,  0.02047164],\n",
       "       [-0.0404057 , -0.03201417, -0.04534901],\n",
       "       [ 0.01393386, -0.04424917, -0.01094481]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wte(np.array([1, 2, 3, 4, 5]))  # Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102ea4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<Variable path=embedding/embeddings, shape=(10, 3), dtype=float32, value=[[ 1.02963559e-02  4.80997562e-03  1.83694065e-05]\n",
       "   [-2.86093485e-02  9.74352285e-03  4.08409499e-02]\n",
       "   [-4.97707501e-02 -3.76918800e-02 -3.74841206e-02]\n",
       "   [-1.95264705e-02 -1.11439116e-02  2.04716437e-02]\n",
       "   [-4.04057018e-02 -3.20141688e-02 -4.53490131e-02]\n",
       "   [ 1.39338635e-02 -4.42491658e-02 -1.09448060e-02]\n",
       "   [-2.34466791e-02 -3.12236678e-02 -2.88974494e-04]\n",
       "   [-2.81121023e-02 -4.56346646e-02  3.39681022e-02]\n",
       "   [-3.66366282e-02  8.73392820e-03  2.19239853e-02]\n",
       "   [-7.10852072e-03  4.43816446e-02 -2.46741623e-03]]>],\n",
       " <Variable path=embedding/embeddings, shape=(10, 3), dtype=float32, value=[[ 1.02963559e-02  4.80997562e-03  1.83694065e-05]\n",
       "  [-2.86093485e-02  9.74352285e-03  4.08409499e-02]\n",
       "  [-4.97707501e-02 -3.76918800e-02 -3.74841206e-02]\n",
       "  [-1.95264705e-02 -1.11439116e-02  2.04716437e-02]\n",
       "  [-4.04057018e-02 -3.20141688e-02 -4.53490131e-02]\n",
       "  [ 1.39338635e-02 -4.42491658e-02 -1.09448060e-02]\n",
       "  [-2.34466791e-02 -3.12236678e-02 -2.88974494e-04]\n",
       "  [-2.81121023e-02 -4.56346646e-02  3.39681022e-02]\n",
       "  [-3.66366282e-02  8.73392820e-03  2.19239853e-02]\n",
       "  [-7.10852072e-03  4.43816446e-02 -2.46741623e-03]]>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wte.weights, wte.embeddings  # Accessing weights, kernel, and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507b065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.8125 0.0625 0.328125]\n",
      " [0.859375 0.5625 0.84375]\n",
      " [0.429688 0.3125 0.0234375]\n",
      " [0.265625 0.335938 0.273438]\n",
      " [0.0859375 0.875 0.742188]\n",
      " [0.34375 0.570312 0.898438]\n",
      " [0.523438 0.484375 0.742188]\n",
      " [0.148438 0.359375 0]\n",
      " [0.320312 0.289062 0.484375]\n",
      " [0.6875 0.3125 0.53125]], shape=(10, 3), dtype=bfloat16) <dtype: 'bfloat16'>\n",
      "tf.Tensor(\n",
      "[[0.660156 0.00390625 0.107422]\n",
      " [0.738281 0.316406 0.710938]\n",
      " [0.18457 0.0976562 0.000549316]\n",
      " [0.0703125 0.112793 0.074707]\n",
      " [0.00738525 0.765625 0.550781]\n",
      " [0.118164 0.326172 0.808594]\n",
      " [0.273438 0.234375 0.550781]\n",
      " [0.0219727 0.128906 0]\n",
      " [0.102539 0.0834961 0.234375]\n",
      " [0.472656 0.0976562 0.28125]], shape=(10, 3), dtype=bfloat16) <dtype: 'bfloat16'>\n"
     ]
    }
   ],
   "source": [
    "r = tf.random.uniform(shape=(10, 3), dtype=tf.bfloat16)\n",
    "print(r, r.dtype)  # Example of random tensor with bfloat16 dtype\n",
    "r2 = r * r\n",
    "print(r2, r2.dtype)  # Example of element-wise multiplication with bfloat16 dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(160000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model,\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f01ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Encoding for position 33329 and d_model 512:\n",
      "[[[ 0.0000000e+00  1.0000000e+00  0.0000000e+00 ...  1.0000000e+00\n",
      "    0.0000000e+00  1.0000000e+00]\n",
      "  [ 8.4147096e-01  5.4030228e-01  8.1589204e-01 ...  1.0000000e+00\n",
      "    6.5495069e-06  1.0000000e+00]\n",
      "  [ 9.0929741e-01 -4.1614684e-01  9.4350451e-01 ...  1.0000000e+00\n",
      "    1.3099014e-05  1.0000000e+00]\n",
      "  ...\n",
      "  [-1.4868733e-02  9.9988943e-01  3.2450861e-01 ...  9.7395545e-01\n",
      "    2.1653989e-01  9.7627378e-01]\n",
      "  [ 8.3334434e-01  5.5275416e-01 -5.8410597e-01 ...  9.7395390e-01\n",
      "    2.1654628e-01  9.7627234e-01]\n",
      "  [ 9.1538447e-01 -4.0258074e-01 -9.9997371e-01 ...  9.7395235e-01\n",
      "    2.1655267e-01  9.7627091e-01]]]\n",
      "Shape: (1, 33329, 512)\n",
      "Data type: <dtype: 'float32'>\n",
      "Size in bytes: 68257792\n",
      "Size in MB: 65.095703125 MB\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "d_model = 512\n",
    "position = random.randint(1, 160000)\n",
    "pos_encoding = positional_encoding(position, d_model)\n",
    "print(f\"Positional Encoding for position {position} and d_model {d_model}:\\n{pos_encoding.numpy()}\")\n",
    "print(f\"Shape: {pos_encoding.shape}\")\n",
    "print(f\"Data type: {pos_encoding.dtype}\")\n",
    "print(f\"Size in bytes: {pos_encoding.numpy().nbytes}\")\n",
    "print(f\"Size in MB: {pos_encoding.numpy().nbytes / (1024 * 1024)} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6fa8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size, strides_format=\"independent\"):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        if strides_format == \"independent\":\n",
    "            self.strides = [1, self.patch_size, self.patch_size, 1]\n",
    "        elif strides_format == \"overlapping\":\n",
    "            self.strides = [1, self.patch_size // 2, self.patch_size // 2, 1]\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=self.strides,\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        print(f\"Extracted patches shape: {patches.shape}\")\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        result = np.zeros(shape=(patches.shape[0], patches.shape[1] + 2, patches.shape[2]))\n",
    "        result[:, 1:-1, :] = patches\n",
    "        result[:, -1, :] = 1\n",
    "        return tf.convert_to_tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e2ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted patches shape: (1, 8, 8, 768)\n",
      "Patches shape: (1, 66, 768)\n"
     ]
    }
   ],
   "source": [
    "layer = Patches(16)\n",
    "image = tf.random.uniform((1, 128, 128, 3), dtype=tf.float32)\n",
    "patches = layer(image)\n",
    "print(f\"Patches shape: {patches.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
